import { Worker, Queue } from 'bullmq'
import { PrismaClient } from '@prisma/client'
import { JobController } from '@/controllers/jobController'

// Configuraci√≥n de Redis
const redisConnection = {
  host: process.env.REDIS_HOST || 'localhost',
  port: parseInt(process.env.REDIS_PORT || '6379'),
  password: process.env.REDIS_PASSWORD
}

// Queue para jobs de scraping
export const jobScrapingQueue = new Queue('job-scraping', { 
  connection: redisConnection,
  defaultJobOptions: {
    removeOnComplete: 10,
    removeOnFail: 5,
    attempts: 3,
    backoff: {
      type: 'exponential',
      delay: 2000
    }
  }
})

const prisma = new PrismaClient()

// Worker para procesar jobs de scraping
export const jobScrapingWorker = new Worker(
  'job-scraping',
  async (job) => {
    console.log(`üîÑ Procesando job de scraping: ${job.id}`)
    
    try {
      const { jobSearchId, type } = job.data
      
      if (type === 'scheduled-scraping') {
        console.log(`üìã Ejecutando scraping programado para: ${jobSearchId}`)
        
        const result = await JobController.executeJobSearch(jobSearchId)
        
        console.log(`‚úÖ Scraping completado:`, {
          jobSearchId,
          newOffersCount: result.newOffersCount,
          keywords: result.keywords
        })
        
        return {
          success: true,
          jobSearchId,
          newOffersCount: result.newOffersCount,
          message: `${result.newOffersCount} nuevas ofertas encontradas`
        }
      }
      
      throw new Error(`Tipo de job desconocido: ${type}`)
      
    } catch (error) {
      console.error(`‚ùå Error en worker de scraping:`, error)
      throw error
    }
  },
  { 
    connection: redisConnection,
    concurrency: 2 // M√°ximo 2 jobs simult√°neos
  }
)

// Manejar eventos del worker
jobScrapingWorker.on('completed', (job, result) => {
  console.log(`‚úÖ Job completado: ${job.id}`, result)
})

jobScrapingWorker.on('failed', (job, err) => {
  console.error(`‚ùå Job fall√≥: ${job?.id}`, err)
})

jobScrapingWorker.on('error', (err) => {
  console.error('‚ùå Error en worker:', err)
})

// Funci√≥n para programar scraping autom√°tico
export async function schedulePeriodicScraping() {
  try {
    console.log('üîÑ Configurando scraping autom√°tico...')
    
    // Obtener todas las b√∫squedas activas
    const activeSearches = await prisma.jobSearch.findMany({
      where: { isActive: true }
    })
    
    console.log(`üìä ${activeSearches.length} b√∫squedas activas encontradas`)
    
    // Limpiar jobs existentes para evitar duplicados
    await jobScrapingQueue.obliterate({ force: true })
    
    // Programar cada b√∫squeda
    for (const search of activeSearches) {
      const jobId = `scraping-${search.id}`
      
      await jobScrapingQueue.add(
        'scheduled-scraping',
        {
          jobSearchId: search.id,
          type: 'scheduled-scraping',
          keywords: search.keywords
        },
        {
          jobId,
          repeat: {
            every: search.frequencyMinutes * 60 * 1000 // Convertir minutos a ms
          }
        }
      )
      
      console.log(`‚è∞ Job programado: ${search.keywords} (cada ${search.frequencyMinutes} min)`)
    }
    
    console.log('‚úÖ Scraping autom√°tico configurado correctamente')
    
  } catch (error) {
    console.error('‚ùå Error configurando scraping autom√°tico:', error)
  }
}

// Funci√≥n para agregar un job de scraping manual
export async function addManualScrapingJob(jobSearchId: string) {
  try {
    const job = await jobScrapingQueue.add(
      'manual-scraping',
      {
        jobSearchId,
        type: 'scheduled-scraping' // Usar el mismo tipo
      },
      {
        priority: 10 // Mayor prioridad para scraping manual
      }
    )
    
    console.log(`üöÄ Job de scraping manual agregado: ${job.id}`)
    return job
    
  } catch (error) {
    console.error('‚ùå Error agregando job manual:', error)
    throw error
  }
}

// Funci√≥n para actualizar la programaci√≥n cuando cambia una b√∫squeda
export async function updateJobSchedule(jobSearchId: string) {
  try {
    console.log(`üîÑ Actualizando programaci√≥n para: ${jobSearchId}`)
    
    // Remover job existente
    const existingJobs = await jobScrapingQueue.getJobs(['delayed', 'waiting', 'active'])
    for (const job of existingJobs) {
      if (job.data.jobSearchId === jobSearchId) {
        await job.remove()
        console.log(`üóëÔ∏è Job anterior removido: ${job.id}`)
      }
    }
    
    // Obtener datos actualizados
    const search = await prisma.jobSearch.findUnique({
      where: { id: jobSearchId }
    })
    
    if (!search) {
      console.log('‚è≠Ô∏è B√∫squeda no encontrada, no se programa')
      return
    }
    
    if (!search.isActive) {
      console.log('‚è≠Ô∏è B√∫squeda inactiva, no se programa')
      return
    }
    
    // Programar nuevo job
    await jobScrapingQueue.add(
      'scheduled-scraping',
      {
        jobSearchId: search.id,
        type: 'scheduled-scraping',
        keywords: search.keywords
      },
      {
        jobId: `scraping-${search.id}`,
        repeat: {
          every: search.frequencyMinutes * 60 * 1000
        }
      }
    )
    
    console.log(`‚úÖ Nueva programaci√≥n configurada: ${search.keywords}`)
    
  } catch (error) {
    console.error('‚ùå Error actualizando programaci√≥n:', error)
  }
}

// Funci√≥n para remover jobs de una b√∫squeda
export async function removeJobSchedule(jobSearchId: string) {
  try {
    console.log(`üóëÔ∏è Removiendo programaci√≥n para: ${jobSearchId}`)
    
    const jobs = await jobScrapingQueue.getJobs(['delayed', 'waiting', 'active'])
    for (const job of jobs) {
      if (job.data.jobSearchId === jobSearchId) {
        await job.remove()
        console.log(`üóëÔ∏è Job removido: ${job.id}`)
      }
    }
    
  } catch (error) {
    console.error('‚ùå Error removiendo jobs:', error)
  }
}

// Funci√≥n para obtener estad√≠sticas de la queue
export async function getQueueStats() {
  try {
    const [waiting, active, completed, failed, delayed] = await Promise.all([
      jobScrapingQueue.getWaiting(),
      jobScrapingQueue.getActive(),
      jobScrapingQueue.getCompleted(),
      jobScrapingQueue.getFailed(),
      jobScrapingQueue.getDelayed()
    ])
    
    return {
      waiting: waiting.length,
      active: active.length,
      completed: completed.length,
      failed: failed.length,
      delayed: delayed.length,
      total: waiting.length + active.length + completed.length + failed.length + delayed.length
    }
    
  } catch (error) {
    console.error('‚ùå Error obteniendo estad√≠sticas:', error)
    return null
  }
}

// Funci√≥n de cleanup para desarrollo
export async function cleanup() {
  try {
    await jobScrapingWorker.close()
    await jobScrapingQueue.close()
    console.log('üîí Conexiones cerradas correctamente')
  } catch (error) {
    console.error('‚ùå Error en cleanup:', error)
  }
}

// Inicializar en el arranque (solo en production)
if (process.env.NODE_ENV === 'production') {
  console.log('üöÄ Inicializando sistema de jobs programados...')
  
  // Esperar un poco para que la DB est√© lista
  setTimeout(() => {
    schedulePeriodicScraping().catch(error => {
      console.error('‚ùå Error iniciando jobs programados:', error)
    })
  }, 5000)
}

export default {
  queue: jobScrapingQueue,
  worker: jobScrapingWorker,
  schedulePeriodicScraping,
  addManualScrapingJob,
  updateJobSchedule,
  removeJobSchedule,
  getQueueStats,
  cleanup
}